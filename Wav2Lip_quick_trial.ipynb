{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sai-darshan-k/SPR/blob/main/Wav2Lip_quick_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSQFs_G8caeE"
      },
      "source": [
        "# Collab preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ac2f48-1680-45c0-fdb3-7a6587f3c9fa"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97571386-9445-4b6e-b681-f5dc1d58615c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# Get the code and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fb141f-b1d3-484f-c817-6f534a79277f"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 400, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 400 (delta 12), reused 1 (delta 1), pack-reused 384 (from 4)\u001b[K\n",
            "Receiving objects: 100% (400/400), 539.91 KiB | 6.92 MiB/s, done.\n",
            "Resolving deltas: 100% (222/222), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b8ee41-2809-4fed-cfa1-fe77973104c5"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Wav2Lip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/MyDrive/Wav2Lip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI",
        "outputId": "20515763-159f-4640-8dc5-6bd8665d1758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Wav2Lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/gdrive/MyDrive/Wav2Lip/wav2lip_gan.pth': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTaOS3ncFt6"
      },
      "source": [
        "# Get the pre-requisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26436fc6-a392-4118-abfd-36d64ef67e06"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.11/dist-packages/tensorflow-2.18.0.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "y\n",
            "Y\n",
            "Yes\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9e2582-8604-4fb0-fb0e-fd581677bc43"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa==0.7.0 (from -r requirements.txt (line 1))\n",
            "  Downloading librosa-0.7.0.tar.gz (1.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.17.1 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.17.1.zip (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84, 4.11.0.86)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5642c71-f08d-4cb0-c729-254af7c0b3e9"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-09 12:18:13--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  17.9MB/s    in 6.0s    \n",
            "\n",
            "2025-02-09 12:18:20 (14.2 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# Now lets try!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1fc88a-83ac-4d23-a3a9-256f345a1e9d"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/test.mp4\" \"/content/gdrive/My Drive/Wav2Lip/test.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/Wav2Lip/test.mp4': No such file or directory\n",
            "cp: cannot stat '/content/gdrive/My Drive/Wav2Lip/test.wav': No such file or directory\n",
            "anscombe.json\t\t     california_housing_train.csv  mnist_train_small.csv\n",
            "california_housing_test.csv  mnist_test.csv\t\t   README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398ced79-3bbc-426a-9cab-65caeaabad39"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/response.mp3\" --audio \"/content/sample_data/response.mp3\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 0\n",
            "Extracting raw audio...\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[mp3 @ 0x5c0d7957f100] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, mp3, from '/content/sample_data/response.mp3':\n",
            "  Duration: 00:00:26.42, start: 0.000000, bitrate: 64 kb/s\n",
            "  Stream #0:0: Audio: mp3, 24000 Hz, mono, fltp, 64 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'temp/temp.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=    1239kB time=00:00:26.40 bitrate= 384.4kbits/s speed= 755x    \n",
            "video:0kB audio:1239kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.006150%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 225, in main\n",
            "    mel = audio.melspectrogram(wav)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/audio.py\", line 47, in melspectrogram\n",
            "    S = _amp_to_db(_linear_to_mel(np.abs(D))) - hp.ref_level_db\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/audio.py\", line 95, in _linear_to_mel\n",
            "    _mel_basis = _build_mel_basis()\n",
            "                 ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/audio.py\", line 100, in _build_mel_basis\n",
            "    return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: mel() takes 0 positional arguments but 2 positional arguments (and 3 keyword-only arguments) were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **Variations to try**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9A9VDVbZAG"
      },
      "source": [
        "1.   Use more padding to include the chin region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154e0957-46c9-46b5-e167-c8e06bed61b9"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/response.mp3\" --audio \"../sample_data/sdfnsdkgnjksdgv.wav\" --pads 0 20 0 0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 183, in main\n",
            "    raise ValueError('--face argument must be a valid path to video/image file')\n",
            "ValueError: --face argument must be a valid path to video/image file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8",
        "outputId": "b5e70965-4d17-45d4-8905-cdf74f1f62f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 183, in main\n",
            "    raise ValueError('--face argument must be a valid path to video/image file')\n",
            "ValueError: --face argument must be a valid path to video/image file\n"
          ]
        }
      ]
    }
  ]
}